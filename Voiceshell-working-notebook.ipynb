{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voiceshell Work Notebook\n",
    "\n",
    "*Adapted from Allison Parrish's Understanding Word Vectors notebook*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python Package Installation for Speech Recognition\n",
    "\n",
    "*Run in terminal to install SpeechRecognition.py & PocketSphinx engine:*\n",
    "\n",
    "`pip install SpeechRecognition`\n",
    "\n",
    "`pip install pocketsphinx`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import math\n",
    "import random\n",
    "from __future__ import unicode_literals\n",
    "import spacy\n",
    "import speech_recognition as sr\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining basic mathematical functions for vector math:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def meanv(coords):\n",
    "    sumv = [0] * len(coords[0])\n",
    "    for item in coords:\n",
    "        for i in range(len(item)):\n",
    "            sumv[i] += item[i]\n",
    "    mean = [0] * len(sumv)\n",
    "    for i in range(len(sumv)):\n",
    "        mean[i] = float(sumv[i]) / len(coords)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine(v1, v2):\n",
    "    if norm(v1) > 0 and norm(v2) > 0:\n",
    "        return dot(v1, v2) / (norm(v1) * norm(v2))\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Spacy/Word Vector low level functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentvec(s):\n",
    "    sent = nlp(s)\n",
    "    return meanv([w.vector for w in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spacy_closest_sent(space, input_str, n=1):\n",
    "    input_vec = sentvec(input_str)\n",
    "    return sorted(space,\n",
    "                  key=lambda x: cosine(np.mean([w.vector for w in x], axis=0), input_vec),\n",
    "                  reverse=True)[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Spacy processor and loading a corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "doc = nlp(open(\"corpus/andrews1.txt\").read().replace('\\n', ' ').replace('  ', ' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting corpus into individual, complete sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = list(doc.sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define list of prompts to user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inquiries = [\"How are you feeling?\", \"Tell me a quote you like.\", \"What are the first three words that pop into your head?\", \"What day is it today?\", \"What's your favourite colour?\", \"Where are you right now?\", \"What's your job?\", \"What do you like to eat?\", \"What animal would you want as a pet?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A buckling dent.\n"
     ]
    }
   ],
   "source": [
    "print(sentences[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining user input prompts, and getting input to process, return result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What day is it today?\n",
      "Tuesday\n",
      "---\n",
      "0\n",
      "White Saris.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "inquiry = random.choice(inquiries)\n",
    "print(inquiry)\n",
    "user_input = input()\n",
    "\n",
    "for sent in spacy_closest_sent(sentences, user_input):\n",
    "    sentNum = sentences.index(sent)\n",
    "    print(\"---\")\n",
    "    print(sentNum)\n",
    "    print(sent.text)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up basic SpeechRecognition input:\n",
    "[Source](http://www.codesofinterest.com/2017/03/python-speech-recognition-pocketsphinx.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just a moment, calibrating the microphone...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-52aa675f2e23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Just a moment, calibrating the microphone...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# 5 second listen and find ambient noise level\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_for_ambient_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0minquiry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minquiries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/speech_recognition/__init__.py\u001b[0m in \u001b[0;36madjust_for_ambient_noise\u001b[0;34m(self, source, duration)\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mseconds_per_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0melapsed_time\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHUNK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m             \u001b[0menergy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudioop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAMPLE_WIDTH\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# energy of the audio signal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/speech_recognition/__init__.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyaudio_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/pyaudio.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    606\u001b[0m                           paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_read_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# get microphone input\n",
    "r = sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Just a moment, calibrating the microphone...\")\n",
    "    # 5 second listen and find ambient noise level\n",
    "    r.adjust_for_ambient_noise(source, duration=5)\n",
    "    inquiry = random.choice(inquiries)\n",
    "    \n",
    "    # read question aloud and print it\n",
    "    os.system(\"say '\" + inquiry + \"'\")\n",
    "    print(inquiry,\" (Speak aloud, please.)\")\n",
    "    audio = r.listen(source)\n",
    "    \n",
    "# recognise speech with Sphinx\n",
    "try:\n",
    "    recogSpeech = r.recognize_sphinx(audio) + \"'\"\n",
    "    print(\"I heard you say: \", recogSpeech)\n",
    "    for sent in spacy_closest_sent(sentences, recogSpeech):\n",
    "        print(\"----------\")\n",
    "        print(\"...\")\n",
    "        print(sent.text)\n",
    "        print(\"----------\")\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Sorry, I couldn't understand you.\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Sphinx error; {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"say 'White Saris, by Angela Andrews'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing lookup of audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First sentence is White Saris\n",
      "Look for that sentence in the file PoemsAudio/Andrews/andrews0.wav\n"
     ]
    }
   ],
   "source": [
    "with open('revisedCorpus/voiceshell_audio_LUT.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    all_lines = list(reader)\n",
    "    \n",
    "audio_lookup_table ={}\n",
    "for line in all_lines:\n",
    "    sentence = line[0]\n",
    "    filename = line[1]\n",
    "    audio_lookup_table[sentence] = filename\n",
    "    \n",
    "example_sentence = all_lines[0][0]\n",
    "print(\"First sentence is {}\".format(example_sentence))\n",
    "example_audiofile = audio_lookup_table[example_sentence]\n",
    "print(\"Look for that sentence in the file {}\".format(example_audiofile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Playing with Python WAV Audio playback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What animal would you want as a pet?\n",
      "cat\n",
      "---\n",
      "10\n",
      "How silk might hang in a cold wardrobe.\n",
      "---\n",
      "PoemsAudio/Andrews/andrews10.wav\n"
     ]
    }
   ],
   "source": [
    "import wave, sys, pyaudio\n",
    "\n",
    "inquiry = random.choice(inquiries)\n",
    "print(inquiry)\n",
    "user_input = input()\n",
    "\n",
    "for sent in spacy_closest_sent(sentences, user_input):\n",
    "    sentNum = sentences.index(sent)\n",
    "    print(\"---\")\n",
    "    print(sentNum)\n",
    "    print(sent.text)\n",
    "    print(\"---\")\n",
    "\n",
    "    audioFile = 'PoemsAudio/Andrews/andrews{}.wav'.format(sentNum)\n",
    "\n",
    "# sound = wave.open(audioFile)\n",
    "\n",
    "print(audioFile)\n",
    "\n",
    "sound = wave.open(audioFile)\n",
    "p = pyaudio.PyAudio()\n",
    "chunk = 1024\n",
    "stream = p.open(format = p.get_format_from_width(sound.getsampwidth()), channels = sound.getnchannels(), rate = sound.getframerate(), output = True)\n",
    "data = sound.readframes(chunk)\n",
    "while len(data) > 0:\n",
    "    stream.write(data)\n",
    "    data = sound.readframes(chunk)\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "\n",
    "p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lookup_table = {}\n",
    "# for each line in csv:\n",
    "   1) text = column[1]\n",
    "   2) filename = column[2]\n",
    "   lookup_table[text] = filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "audio_file = lokup_table[closest_sentence]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
